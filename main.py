import requests
import os
import random
import json
import codecs # Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ†
from bs4 import BeautifulSoup

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ ---
BOT_TOKEN = os.environ.get("BOT_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")
PROXIES_URL = "https://raw.githubusercontent.com/MhdiTaheri/ProxyCollector/main/proxy.txt"
TELEGRAM_API_URL = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
SENTENCES_FILE = "sentences.txt"

# --- Ø¢Ø¯Ø±Ø³ Ø¬Ø¯ÛŒØ¯ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ ---
# Ù…Ø§ ÙÙ‚Ø· Ø§Ø±Ø²Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ… ØªØ§ Ø³Ø±Ø¹Øª Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø±ÙˆØ¯
PRICE_API_URL = "https://www.navasan.tech/wp-navasan.php?usd&eur&sekkeh"

# !!! Ù…Ù‡Ù…: Ù„ÛŒÙ†Ú© Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ !!!
TELEGRAM_PROXY_CHANNEL_URL = "https://t.me/YourTelegramProxyChannel"
V2RAY_CHANNEL_URL = "https://t.me/YourV2rayChannel"

def fetch_list_from_file(filename):
    """Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ø§ Ø§Ø² ÛŒÚ© ÙØ§ÛŒÙ„ Ù…Ø­Ù„ÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯."""
    try:
        with open(filename, "r", encoding="utf-8") as f:
            return [line.strip() for line in f if line.strip()]
    except Exception as e:
        print(f"Error reading file {filename}: {e}")
        return []

def get_prices_from_api():
    """Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² API ØºÛŒØ±Ø±Ø³Ù…ÛŒ Navasan Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯ Ùˆ Ø®Ø·Ø§ÛŒØ§Ø¨ÛŒ Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯."""
    prices = {}
    try:
        print("Fetching currency prices from Navasan API...")
        url = "https://www.navasan.tech/wp-navasan.php?usd&eur&sekkeh"
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        
        raw_js = response.text
        start = raw_js.find("('\"") + 3
        end = raw_js.rfind("\"')")
        if start == 2 or end == -1:
            raise ValueError("Could not find the start/end pattern in the JS response.")
            
        html_escaped_string = raw_js[start:end]
        
        # --- Ø¨Ø®Ø´ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ø®Ø·Ø§ ---
        # Ø§Ú¯Ø± Ø±Ø´ØªÙ‡ Ø¨Ø§ ÛŒÚ© Ø¨Ú©â€ŒØ§Ø³Ù„Ø´ ØªÙ†Ù‡Ø§ ØªÙ…Ø§Ù… Ø´Ø¯Ù‡ Ø¨ÙˆØ¯ØŒ Ø¢Ù† Ø±Ø§ Ø­Ø°Ù Ú©Ù†
        if html_escaped_string.endswith('\\'):
            html_escaped_string = html_escaped_string[:-1]
        # --- Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ ---

        html_string = codecs.decode(html_escaped_string, 'unicode_escape')
        soup = BeautifulSoup(html_string, 'lxml')
        
        targets = {'usd': "tr#usd", 'eur': "tr#eur", 'sekeh': "tr#sekkeh"}
        for name, selector in targets.items():
            element = soup.select_one(f"{selector} > td.val")
            if element:
                prices[name] = element.text.strip()
            else:
                print(f"Warning: Could not find the element for '{name}'.")
                prices[name] = "N/A"
        
        if all(value == "N/A" for value in prices.values()):
             raise ValueError("Failed to extract any prices. HTML structure likely changed.")

        print(f"Prices fetched successfully: {prices}")
        return prices
    except Exception as e:
        print(f"An exception occurred in get_prices_from_api: {e}")
        return None

def send_final_message(sentence, prices, proxies_list):
    """Ù¾ÛŒØ§Ù… Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ØªØ±Ú©ÛŒØ¨ÛŒ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    # Ø¨Ø®Ø´ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§
    price_text = "ğŸ“Š **Ø¢Ø®Ø±ÛŒÙ† Ù†Ø±Ø® Ø§Ø±Ø² Ùˆ Ø·Ù„Ø§:**\n\n"
    if prices:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ¯ <code> Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ± Ø§Ø¹Ø¯Ø§Ø¯
        price_text += (
            f"ğŸ’µ Ø¯Ù„Ø§Ø± Ø¢Ù…Ø±ÛŒÚ©Ø§: <code>{prices.get('usd', 'N/A')}</code>\n"
            f"ğŸ‡ªğŸ‡º ÛŒÙˆØ±Ùˆ: <code>{prices.get('eur', 'N/A')}</code>\n"
            f"ğŸª™ Ø³Ú©Ù‡ Ø§Ù…Ø§Ù…ÛŒ: <code>{prices.get('sekeh', 'N/A')}</code>"
        )
    else:
        price_text += "Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªÙ†Ø¯."
        
    # Ø¨Ø®Ø´ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
    proxy_buttons = [{"text": f"âœ… Proxy {i + 1}", "url": p} for i, p in enumerate(proxies_list)]
    channel_buttons = [
        {"text": "ğŸš€ Ú©Ø§Ù†Ø§Ù„ Ù¾Ø±ÙˆÚ©Ø³ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…", "url": TELEGRAM_PROXY_CHANNEL_URL},
        {"text": "âš¡ï¸ Ú©Ø§Ù†Ø§Ù„ V2ray Ø±Ø§ÛŒÚ¯Ø§Ù†", "url": V2RAY_CHANNEL_URL}
    ]
    keyboard = [proxy_buttons, channel_buttons]
    reply_markup = json.dumps({"inline_keyboard": keyboard})

    # ØªØ±Ú©ÛŒØ¨ Ù†Ù‡Ø§ÛŒÛŒ Ù¾ÛŒØ§Ù…
    message_text = (
        f"{sentence}\n\n"
        f"------------------------------\n"
        f"{price_text}\n\n"
        f"ğŸ‘‡ Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„ØŒ ÛŒÚ©ÛŒ Ø§Ø² Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:"
    )

    payload = {'chat_id': CHAT_ID, 'text': message_text, 'parse_mode': 'HTML', 'reply_markup': reply_markup}
    
    requests.post(TELEGRAM_API_URL, data=payload, timeout=10)
    print("Final combined message sent to Telegram.")

# --- Ù…Ù†Ø·Ù‚ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ ---
if __name__ == "__main__":
    # Û±. Ø®ÙˆØ§Ù†Ø¯Ù† Ø¬Ù…Ù„Ø§Øª
    sentences = fetch_list_from_file(SENTENCES_FILE)
    chosen_sentence = random.choice(sentences) if sentences else "Ù…ÙˆÙÙ‚ÛŒØªØŒ Ù†ØªÛŒØ¬Ù‡â€ŒÛŒ ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ùˆ Ø±ÙˆØ²Ù…Ø±Ù‡ Ø§Ø³Øª."

    # Û². Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ø§Ø² API Ø¬Ø¯ÛŒØ¯
    current_prices = get_prices_from_api()

    # Û³. Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§
    try:
        proxies_text = requests.get(PROXIES_URL, timeout=15).text
        all_proxies = [p for p in proxies_text.strip().split('\n') if '://' in p]
        
        if len(all_proxies) >= 3:
            selected_proxies = random.sample(all_proxies, 3)
            # Û´. Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ù†Ù‡Ø§ÛŒÛŒ
            send_final_message(chosen_sentence, current_prices, selected_proxies)
        else:
            print("Not enough proxies found.")
    except Exception as e:
        print(f"Failed to fetch proxies: {e}")
